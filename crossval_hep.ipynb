{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats as st\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 200\n",
    "data = pd.read_csv('clean_hep.csv', index_col='CASEID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25403, 70)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HEP_BILELEAKAGE']\n",
    "X = data.drop(['HEP_BILELEAKAGE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "fold_no=0\n",
    "for train_index, test_index in skf.split(data, y):\n",
    "    train = data.loc[train_index,:]\n",
    "    test = data.loc[test_index,:]\n",
    "    train_filename = 'train' + str(fold_no) + '.csv'\n",
    "    test_filename = 'test' + str(fold_no) + '.csv' \n",
    "    train.to_csv('splits/' + train_filename, index=False)\n",
    "    test.to_csv('splits/' + test_filename, index=False) \n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for x in range(1,6):\n",
    "    d['train{}'.format(x)] = pd.read_csv('splits/train{}.csv'.format(x), low_memory=False)\n",
    "    d['test{}'.format(x)] = pd.read_csv('splits/test{}.csv'.format(x), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5081\n",
      "5081\n",
      "5081\n",
      "5081\n",
      "5081\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,6):\n",
    "    print(len(d['test1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_train = []\n",
    "dy_train = []\n",
    "for x in d:\n",
    "    if 'train' in x:\n",
    "        dX_train.append(d[x].drop(columns=['HEP_BILELEAKAGE'], axis=1))\n",
    "        dy_train.append(d[x]['HEP_BILELEAKAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_test = []\n",
    "dy_test = []\n",
    "for x in d:\n",
    "    if 'test' in x:\n",
    "        dX_test.append(d[x].drop(columns=['HEP_BILELEAKAGE'], axis=1))\n",
    "        dy_test.append(d[x]['HEP_BILELEAKAGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfpreds = []\n",
    "xgbpreds = []\n",
    "model = RandomForestClassifier(n_estimators=1250, min_samples_split=2, min_samples_leaf=8, max_features='auto', max_depth=20, bootstrap=True)\n",
    "model2 = XGBClassifier(n_estimators=50, subsample=0.6, min_child_weight=10, max_depth=6, learning_rate=0.1, colsample_bytree=0.8)\n",
    "for X, y, X_test in zip(dX_train, dy_train, dX_test):\n",
    "    model.fit(X, y)\n",
    "    model2.fit(X, y)\n",
    "    rfpreds.append(model.predict_proba(X_test))\n",
    "    xgbpreds.append(model2.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%store rfpreds\n",
    "%store xgbpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in range(1,6):\n",
    "    print(roc_auc_score(dy_test[x], rfpreds[x][:,1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in range(1,6):\n",
    "    print(roc_auc_score(dy_test[x], xgbpreds[x][:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "input_shape = [dX_train[1].shape[1]]\n",
    "model4 = keras.models.Sequential()\n",
    "model4.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "model4.add(keras.layers.BatchNormalization())\n",
    "for _ in range(2):\n",
    "    model4.add(keras.layers.Dense(1000))\n",
    "    model4.add(keras.layers.BatchNormalization())\n",
    "    model4.add(keras.layers.Dropout(0.8))\n",
    "    model4.add(keras.layers.Activation(\"relu\"))\n",
    "model4.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "metrics = [keras.metrics.Recall(name='Sensitivity'), keras.metrics.TrueNegatives(name='tn'), keras.metrics.AUC(name='auc'), keras.metrics.AUC(name='prc', curve='PR')]\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=metrics,)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.00001,\n",
    "    restore_best_weights=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - 2s 30ms/step - loss: 0.4475 - Sensitivity: 0.1922 - tn: 12550.0000 - auc: 0.5167 - prc: 0.0415 - val_loss: 1.4602 - val_Sensitivity: 1.0000 - val_tn: 1.0000 - val_auc: 0.6611 - val_prc: 0.0743\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2401 - Sensitivity: 0.0511 - tn: 14386.0000 - auc: 0.5121 - prc: 0.0464 - val_loss: 0.6511 - val_Sensitivity: 0.5879 - val_tn: 3391.0000 - val_auc: 0.6852 - val_prc: 0.0867\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2138 - Sensitivity: 0.0317 - tn: 14502.0000 - auc: 0.5722 - prc: 0.0545 - val_loss: 0.5144 - val_Sensitivity: 0.3618 - val_tn: 4309.0000 - val_auc: 0.6969 - val_prc: 0.0911\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2140 - Sensitivity: 0.0441 - tn: 14474.0000 - auc: 0.6030 - prc: 0.0602 - val_loss: 0.3916 - val_Sensitivity: 0.2312 - val_tn: 4587.0000 - val_auc: 0.7030 - val_prc: 0.0918\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2122 - Sensitivity: 0.0423 - tn: 14512.0000 - auc: 0.5986 - prc: 0.0670 - val_loss: 0.3422 - val_Sensitivity: 0.1910 - val_tn: 4649.0000 - val_auc: 0.7052 - val_prc: 0.0926\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1954 - Sensitivity: 0.0582 - tn: 14529.0000 - auc: 0.6407 - prc: 0.0836 - val_loss: 0.3089 - val_Sensitivity: 0.1809 - val_tn: 4665.0000 - val_auc: 0.7133 - val_prc: 0.0968\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2029 - Sensitivity: 0.0582 - tn: 14520.0000 - auc: 0.6356 - prc: 0.0781 - val_loss: 0.2916 - val_Sensitivity: 0.1910 - val_tn: 4658.0000 - val_auc: 0.7180 - val_prc: 0.0977\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1976 - Sensitivity: 0.0529 - tn: 14521.0000 - auc: 0.6314 - prc: 0.0754 - val_loss: 0.2620 - val_Sensitivity: 0.1859 - val_tn: 4678.0000 - val_auc: 0.7244 - val_prc: 0.1000\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1918 - Sensitivity: 0.0370 - tn: 14542.0000 - auc: 0.6416 - prc: 0.0735 - val_loss: 0.2668 - val_Sensitivity: 0.2060 - val_tn: 4631.0000 - val_auc: 0.7287 - val_prc: 0.0989\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1932 - Sensitivity: 0.0600 - tn: 14518.0000 - auc: 0.6573 - prc: 0.0785 - val_loss: 0.2529 - val_Sensitivity: 0.2010 - val_tn: 4656.0000 - val_auc: 0.7304 - val_prc: 0.1001\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1907 - Sensitivity: 0.0476 - tn: 14540.0000 - auc: 0.6473 - prc: 0.0810 - val_loss: 0.2266 - val_Sensitivity: 0.1759 - val_tn: 4722.0000 - val_auc: 0.7310 - val_prc: 0.1036\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1911 - Sensitivity: 0.0353 - tn: 14567.0000 - auc: 0.6259 - prc: 0.0766 - val_loss: 0.2393 - val_Sensitivity: 0.2010 - val_tn: 4664.0000 - val_auc: 0.7325 - val_prc: 0.1009\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1901 - Sensitivity: 0.0547 - tn: 14527.0000 - auc: 0.6486 - prc: 0.0748 - val_loss: 0.2400 - val_Sensitivity: 0.2060 - val_tn: 4664.0000 - val_auc: 0.7339 - val_prc: 0.1012\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1822 - Sensitivity: 0.0564 - tn: 14568.0000 - auc: 0.6559 - prc: 0.0851 - val_loss: 0.2274 - val_Sensitivity: 0.1508 - val_tn: 4718.0000 - val_auc: 0.7345 - val_prc: 0.1011\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1838 - Sensitivity: 0.0423 - tn: 14575.0000 - auc: 0.6608 - prc: 0.0806 - val_loss: 0.2211 - val_Sensitivity: 0.1558 - val_tn: 4723.0000 - val_auc: 0.7353 - val_prc: 0.1054\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1771 - Sensitivity: 0.0511 - tn: 14582.0000 - auc: 0.6734 - prc: 0.0981 - val_loss: 0.2323 - val_Sensitivity: 0.1709 - val_tn: 4712.0000 - val_auc: 0.7359 - val_prc: 0.1043\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1728 - Sensitivity: 0.0353 - tn: 14582.0000 - auc: 0.6852 - prc: 0.0880 - val_loss: 0.2399 - val_Sensitivity: 0.1859 - val_tn: 4694.0000 - val_auc: 0.7340 - val_prc: 0.1033\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1721 - Sensitivity: 0.0459 - tn: 14583.0000 - auc: 0.6842 - prc: 0.0974 - val_loss: 0.2400 - val_Sensitivity: 0.1759 - val_tn: 4694.0000 - val_auc: 0.7310 - val_prc: 0.1006\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1692 - Sensitivity: 0.0564 - tn: 14588.0000 - auc: 0.7015 - prc: 0.1039 - val_loss: 0.2287 - val_Sensitivity: 0.1608 - val_tn: 4713.0000 - val_auc: 0.7323 - val_prc: 0.1009\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1664 - Sensitivity: 0.0388 - tn: 14597.0000 - auc: 0.7037 - prc: 0.0994 - val_loss: 0.2254 - val_Sensitivity: 0.1457 - val_tn: 4729.0000 - val_auc: 0.7343 - val_prc: 0.1019\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1691 - Sensitivity: 0.0529 - tn: 14586.0000 - auc: 0.7005 - prc: 0.0987 - val_loss: 0.2321 - val_Sensitivity: 0.1508 - val_tn: 4712.0000 - val_auc: 0.7324 - val_prc: 0.0993\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1632 - Sensitivity: 0.0335 - tn: 14615.0000 - auc: 0.7092 - prc: 0.1031 - val_loss: 0.2334 - val_Sensitivity: 0.1005 - val_tn: 4741.0000 - val_auc: 0.7293 - val_prc: 0.0974\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1637 - Sensitivity: 0.0441 - tn: 14604.0000 - auc: 0.7081 - prc: 0.1021 - val_loss: 0.2396 - val_Sensitivity: 0.1055 - val_tn: 4728.0000 - val_auc: 0.7284 - val_prc: 0.0962\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1596 - Sensitivity: 0.0370 - tn: 14623.0000 - auc: 0.7148 - prc: 0.1227 - val_loss: 0.2351 - val_Sensitivity: 0.0905 - val_tn: 4741.0000 - val_auc: 0.7271 - val_prc: 0.0959\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1620 - Sensitivity: 0.0335 - tn: 14615.0000 - auc: 0.7224 - prc: 0.1114 - val_loss: 0.2318 - val_Sensitivity: 0.0905 - val_tn: 4756.0000 - val_auc: 0.7289 - val_prc: 0.0978\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1804 - Sensitivity: 0.0383 - tn: 14572.0000 - auc: 0.6717 - prc: 0.0879 - val_loss: 0.2372 - val_Sensitivity: 0.2318 - val_tn: 4652.0000 - val_auc: 0.7625 - val_prc: 0.1549\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1799 - Sensitivity: 0.0365 - tn: 14544.0000 - auc: 0.6715 - prc: 0.0831 - val_loss: 0.2367 - val_Sensitivity: 0.2000 - val_tn: 4678.0000 - val_auc: 0.7606 - val_prc: 0.1490\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1750 - Sensitivity: 0.0348 - tn: 14583.0000 - auc: 0.6778 - prc: 0.0939 - val_loss: 0.2503 - val_Sensitivity: 0.2182 - val_tn: 4655.0000 - val_auc: 0.7566 - val_prc: 0.1478\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1713 - Sensitivity: 0.0435 - tn: 14578.0000 - auc: 0.6994 - prc: 0.0976 - val_loss: 0.2377 - val_Sensitivity: 0.1500 - val_tn: 4720.0000 - val_auc: 0.7550 - val_prc: 0.1441\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1731 - Sensitivity: 0.0226 - tn: 14610.0000 - auc: 0.6856 - prc: 0.0880 - val_loss: 0.2392 - val_Sensitivity: 0.1545 - val_tn: 4708.0000 - val_auc: 0.7551 - val_prc: 0.1403\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1695 - Sensitivity: 0.0400 - tn: 14581.0000 - auc: 0.6940 - prc: 0.0922 - val_loss: 0.2372 - val_Sensitivity: 0.1545 - val_tn: 4726.0000 - val_auc: 0.7533 - val_prc: 0.1422\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1677 - Sensitivity: 0.0400 - tn: 14610.0000 - auc: 0.6876 - prc: 0.0999 - val_loss: 0.2402 - val_Sensitivity: 0.1727 - val_tn: 4723.0000 - val_auc: 0.7509 - val_prc: 0.1407\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1631 - Sensitivity: 0.0400 - tn: 14605.0000 - auc: 0.7164 - prc: 0.1082 - val_loss: 0.2398 - val_Sensitivity: 0.1727 - val_tn: 4699.0000 - val_auc: 0.7494 - val_prc: 0.1347\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1642 - Sensitivity: 0.0348 - tn: 14607.0000 - auc: 0.6969 - prc: 0.0990 - val_loss: 0.2360 - val_Sensitivity: 0.1545 - val_tn: 4704.0000 - val_auc: 0.7482 - val_prc: 0.1362\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1674 - Sensitivity: 0.0313 - tn: 14611.0000 - auc: 0.6821 - prc: 0.0949 - val_loss: 0.2342 - val_Sensitivity: 0.1500 - val_tn: 4726.0000 - val_auc: 0.7482 - val_prc: 0.1373\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1639 - Sensitivity: 0.0313 - tn: 14620.0000 - auc: 0.6994 - prc: 0.0987 - val_loss: 0.2395 - val_Sensitivity: 0.1545 - val_tn: 4715.0000 - val_auc: 0.7458 - val_prc: 0.1350\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1611 - Sensitivity: 0.0261 - tn: 14611.0000 - auc: 0.7140 - prc: 0.0964 - val_loss: 0.2356 - val_Sensitivity: 0.1318 - val_tn: 4737.0000 - val_auc: 0.7459 - val_prc: 0.1339\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1556 - Sensitivity: 0.0243 - tn: 14633.0000 - auc: 0.7291 - prc: 0.1139 - val_loss: 0.2393 - val_Sensitivity: 0.1591 - val_tn: 4720.0000 - val_auc: 0.7461 - val_prc: 0.1326\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1583 - Sensitivity: 0.0330 - tn: 14618.0000 - auc: 0.7275 - prc: 0.1080 - val_loss: 0.2426 - val_Sensitivity: 0.1636 - val_tn: 4704.0000 - val_auc: 0.7449 - val_prc: 0.1313\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1592 - Sensitivity: 0.0243 - tn: 14620.0000 - auc: 0.7175 - prc: 0.1095 - val_loss: 0.2378 - val_Sensitivity: 0.1318 - val_tn: 4732.0000 - val_auc: 0.7443 - val_prc: 0.1306\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1569 - Sensitivity: 0.0261 - tn: 14628.0000 - auc: 0.7266 - prc: 0.1169 - val_loss: 0.2375 - val_Sensitivity: 0.1182 - val_tn: 4745.0000 - val_auc: 0.7423 - val_prc: 0.1291\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1541 - Sensitivity: 0.0087 - tn: 14631.0000 - auc: 0.7356 - prc: 0.1143 - val_loss: 0.2304 - val_Sensitivity: 0.1091 - val_tn: 4761.0000 - val_auc: 0.7438 - val_prc: 0.1318\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1519 - Sensitivity: 0.0296 - tn: 14634.0000 - auc: 0.7417 - prc: 0.1191 - val_loss: 0.2265 - val_Sensitivity: 0.1045 - val_tn: 4771.0000 - val_auc: 0.7432 - val_prc: 0.1322\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1498 - Sensitivity: 0.0209 - tn: 14629.0000 - auc: 0.7523 - prc: 0.1301 - val_loss: 0.2291 - val_Sensitivity: 0.1091 - val_tn: 4770.0000 - val_auc: 0.7421 - val_prc: 0.1308\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1508 - Sensitivity: 0.0174 - tn: 14639.0000 - auc: 0.7419 - prc: 0.1215 - val_loss: 0.2289 - val_Sensitivity: 0.1091 - val_tn: 4771.0000 - val_auc: 0.7424 - val_prc: 0.1317\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1509 - Sensitivity: 0.0209 - tn: 14648.0000 - auc: 0.7469 - prc: 0.1311 - val_loss: 0.2295 - val_Sensitivity: 0.1045 - val_tn: 4779.0000 - val_auc: 0.7402 - val_prc: 0.1305\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1476 - Sensitivity: 0.0226 - tn: 14642.0000 - auc: 0.7581 - prc: 0.1424 - val_loss: 0.2358 - val_Sensitivity: 0.1182 - val_tn: 4762.0000 - val_auc: 0.7380 - val_prc: 0.1285\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1483 - Sensitivity: 0.0226 - tn: 14643.0000 - auc: 0.7469 - prc: 0.1368 - val_loss: 0.2335 - val_Sensitivity: 0.1045 - val_tn: 4770.0000 - val_auc: 0.7380 - val_prc: 0.1259\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1528 - Sensitivity: 0.0139 - tn: 14644.0000 - auc: 0.7362 - prc: 0.1102 - val_loss: 0.2326 - val_Sensitivity: 0.1045 - val_tn: 4774.0000 - val_auc: 0.7378 - val_prc: 0.1255\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1447 - Sensitivity: 0.0191 - tn: 14646.0000 - auc: 0.7689 - prc: 0.1446 - val_loss: 0.2374 - val_Sensitivity: 0.1182 - val_tn: 4765.0000 - val_auc: 0.7354 - val_prc: 0.1223\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1451 - Sensitivity: 0.0191 - tn: 14647.0000 - auc: 0.7682 - prc: 0.1346 - val_loss: 0.2358 - val_Sensitivity: 0.1136 - val_tn: 4763.0000 - val_auc: 0.7349 - val_prc: 0.1207\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1454 - Sensitivity: 0.0209 - tn: 14650.0000 - auc: 0.7631 - prc: 0.1529 - val_loss: 0.2284 - val_Sensitivity: 0.1045 - val_tn: 4775.0000 - val_auc: 0.7371 - val_prc: 0.1225\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1465 - Sensitivity: 0.0157 - tn: 14644.0000 - auc: 0.7622 - prc: 0.1286 - val_loss: 0.2303 - val_Sensitivity: 0.1136 - val_tn: 4771.0000 - val_auc: 0.7369 - val_prc: 0.1210\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1579 - Sensitivity: 0.0086 - tn: 14638.0000 - auc: 0.7164 - prc: 0.1006 - val_loss: 0.2125 - val_Sensitivity: 0.1222 - val_tn: 4849.0000 - val_auc: 0.7737 - val_prc: 0.1553\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1560 - Sensitivity: 0.0103 - tn: 14639.0000 - auc: 0.7180 - prc: 0.1094 - val_loss: 0.2196 - val_Sensitivity: 0.1278 - val_tn: 4838.0000 - val_auc: 0.7704 - val_prc: 0.1462\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1540 - Sensitivity: 0.0086 - tn: 14650.0000 - auc: 0.7311 - prc: 0.1102 - val_loss: 0.2152 - val_Sensitivity: 0.1111 - val_tn: 4843.0000 - val_auc: 0.7694 - val_prc: 0.1454\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1568 - Sensitivity: 0.0017 - tn: 14647.0000 - auc: 0.7185 - prc: 0.0998 - val_loss: 0.2144 - val_Sensitivity: 0.1056 - val_tn: 4849.0000 - val_auc: 0.7677 - val_prc: 0.1452\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1527 - Sensitivity: 0.0172 - tn: 14650.0000 - auc: 0.7257 - prc: 0.1260 - val_loss: 0.2182 - val_Sensitivity: 0.1167 - val_tn: 4845.0000 - val_auc: 0.7669 - val_prc: 0.1431\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1521 - Sensitivity: 0.0103 - tn: 14649.0000 - auc: 0.7380 - prc: 0.1086 - val_loss: 0.2175 - val_Sensitivity: 0.1111 - val_tn: 4852.0000 - val_auc: 0.7652 - val_prc: 0.1406\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1513 - Sensitivity: 0.0103 - tn: 14645.0000 - auc: 0.7475 - prc: 0.1155 - val_loss: 0.2153 - val_Sensitivity: 0.0944 - val_tn: 4856.0000 - val_auc: 0.7649 - val_prc: 0.1386\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1491 - Sensitivity: 0.0086 - tn: 14646.0000 - auc: 0.7500 - prc: 0.1191 - val_loss: 0.2222 - val_Sensitivity: 0.1000 - val_tn: 4839.0000 - val_auc: 0.7619 - val_prc: 0.1308\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1508 - Sensitivity: 0.0069 - tn: 14646.0000 - auc: 0.7465 - prc: 0.1148 - val_loss: 0.2170 - val_Sensitivity: 0.0944 - val_tn: 4854.0000 - val_auc: 0.7624 - val_prc: 0.1319\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1503 - Sensitivity: 0.0017 - tn: 14648.0000 - auc: 0.7476 - prc: 0.1153 - val_loss: 0.2207 - val_Sensitivity: 0.0944 - val_tn: 4850.0000 - val_auc: 0.7592 - val_prc: 0.1286\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1514 - Sensitivity: 0.0086 - tn: 14648.0000 - auc: 0.7359 - prc: 0.1181 - val_loss: 0.2231 - val_Sensitivity: 0.0944 - val_tn: 4849.0000 - val_auc: 0.7570 - val_prc: 0.1257\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1646 - Sensitivity: 0.0151 - tn: 14622.0000 - auc: 0.7173 - prc: 0.1064 - val_loss: 0.2211 - val_Sensitivity: 0.1341 - val_tn: 4829.0000 - val_auc: 0.7886 - val_prc: 0.1570\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1613 - Sensitivity: 0.0117 - tn: 14620.0000 - auc: 0.7133 - prc: 0.1010 - val_loss: 0.2259 - val_Sensitivity: 0.1341 - val_tn: 4820.0000 - val_auc: 0.7845 - val_prc: 0.1482\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1620 - Sensitivity: 0.0167 - tn: 14625.0000 - auc: 0.7053 - prc: 0.1079 - val_loss: 0.2211 - val_Sensitivity: 0.0950 - val_tn: 4843.0000 - val_auc: 0.7840 - val_prc: 0.1520\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1602 - Sensitivity: 0.0117 - tn: 14628.0000 - auc: 0.7223 - prc: 0.1084 - val_loss: 0.2356 - val_Sensitivity: 0.1229 - val_tn: 4796.0000 - val_auc: 0.7799 - val_prc: 0.1338\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1592 - Sensitivity: 0.0067 - tn: 14626.0000 - auc: 0.7240 - prc: 0.1063 - val_loss: 0.2244 - val_Sensitivity: 0.0950 - val_tn: 4825.0000 - val_auc: 0.7796 - val_prc: 0.1384\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1557 - Sensitivity: 0.0100 - tn: 14629.0000 - auc: 0.7397 - prc: 0.1189 - val_loss: 0.2241 - val_Sensitivity: 0.0838 - val_tn: 4833.0000 - val_auc: 0.7791 - val_prc: 0.1393\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1590 - Sensitivity: 0.0167 - tn: 14623.0000 - auc: 0.7156 - prc: 0.1147 - val_loss: 0.2213 - val_Sensitivity: 0.0782 - val_tn: 4849.0000 - val_auc: 0.7776 - val_prc: 0.1423\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1556 - Sensitivity: 0.0117 - tn: 14627.0000 - auc: 0.7377 - prc: 0.1156 - val_loss: 0.2194 - val_Sensitivity: 0.0782 - val_tn: 4853.0000 - val_auc: 0.7772 - val_prc: 0.1391\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1532 - Sensitivity: 0.0151 - tn: 14636.0000 - auc: 0.7432 - prc: 0.1335 - val_loss: 0.2178 - val_Sensitivity: 0.0615 - val_tn: 4856.0000 - val_auc: 0.7781 - val_prc: 0.1410\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1548 - Sensitivity: 0.0033 - tn: 14632.0000 - auc: 0.7352 - prc: 0.1146 - val_loss: 0.2208 - val_Sensitivity: 0.0726 - val_tn: 4848.0000 - val_auc: 0.7762 - val_prc: 0.1373\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1511 - Sensitivity: 0.0117 - tn: 14633.0000 - auc: 0.7521 - prc: 0.1383 - val_loss: 0.2182 - val_Sensitivity: 0.0726 - val_tn: 4853.0000 - val_auc: 0.7758 - val_prc: 0.1392\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1535 - Sensitivity: 0.0050 - tn: 14634.0000 - auc: 0.7411 - prc: 0.1253 - val_loss: 0.2226 - val_Sensitivity: 0.0726 - val_tn: 4845.0000 - val_auc: 0.7738 - val_prc: 0.1351\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1527 - Sensitivity: 0.0100 - tn: 14629.0000 - auc: 0.7471 - prc: 0.1291 - val_loss: 0.2315 - val_Sensitivity: 0.0838 - val_tn: 4814.0000 - val_auc: 0.7720 - val_prc: 0.1224\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1504 - Sensitivity: 0.0100 - tn: 14630.0000 - auc: 0.7530 - prc: 0.1271 - val_loss: 0.2224 - val_Sensitivity: 0.0670 - val_tn: 4830.0000 - val_auc: 0.7713 - val_prc: 0.1239\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1533 - Sensitivity: 0.0033 - tn: 14629.0000 - auc: 0.7380 - prc: 0.1210 - val_loss: 0.2200 - val_Sensitivity: 0.0670 - val_tn: 4844.0000 - val_auc: 0.7728 - val_prc: 0.1306\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1489 - Sensitivity: 0.0167 - tn: 14633.0000 - auc: 0.7620 - prc: 0.1344 - val_loss: 0.2216 - val_Sensitivity: 0.0782 - val_tn: 4825.0000 - val_auc: 0.7715 - val_prc: 0.1225\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1511 - Sensitivity: 0.0084 - tn: 14633.0000 - auc: 0.7546 - prc: 0.1301 - val_loss: 0.2174 - val_Sensitivity: 0.0670 - val_tn: 4830.0000 - val_auc: 0.7724 - val_prc: 0.1241\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1485 - Sensitivity: 0.0084 - tn: 14636.0000 - auc: 0.7656 - prc: 0.1349 - val_loss: 0.2190 - val_Sensitivity: 0.0670 - val_tn: 4828.0000 - val_auc: 0.7718 - val_prc: 0.1205\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1460 - Sensitivity: 0.0067 - tn: 14638.0000 - auc: 0.7727 - prc: 0.1527 - val_loss: 0.2209 - val_Sensitivity: 0.0782 - val_tn: 4822.0000 - val_auc: 0.7698 - val_prc: 0.1141\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1467 - Sensitivity: 0.0151 - tn: 14632.0000 - auc: 0.7729 - prc: 0.1417 - val_loss: 0.2150 - val_Sensitivity: 0.0670 - val_tn: 4832.0000 - val_auc: 0.7708 - val_prc: 0.1184\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1489 - Sensitivity: 0.0067 - tn: 14638.0000 - auc: 0.7638 - prc: 0.1371 - val_loss: 0.2141 - val_Sensitivity: 0.0670 - val_tn: 4835.0000 - val_auc: 0.7697 - val_prc: 0.1222\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1489 - Sensitivity: 0.0067 - tn: 14635.0000 - auc: 0.7598 - prc: 0.1390 - val_loss: 0.2140 - val_Sensitivity: 0.0670 - val_tn: 4833.0000 - val_auc: 0.7693 - val_prc: 0.1197\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1472 - Sensitivity: 0.0067 - tn: 14637.0000 - auc: 0.7724 - prc: 0.1418 - val_loss: 0.2113 - val_Sensitivity: 0.0670 - val_tn: 4837.0000 - val_auc: 0.7691 - val_prc: 0.1277\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1467 - Sensitivity: 0.0017 - tn: 14633.0000 - auc: 0.7721 - prc: 0.1467 - val_loss: 0.2118 - val_Sensitivity: 0.0670 - val_tn: 4834.0000 - val_auc: 0.7688 - val_prc: 0.1220\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1480 - Sensitivity: 0.0084 - tn: 14629.0000 - auc: 0.7644 - prc: 0.1484 - val_loss: 0.2173 - val_Sensitivity: 0.0670 - val_tn: 4833.0000 - val_auc: 0.7679 - val_prc: 0.1172\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1444 - Sensitivity: 0.0017 - tn: 14639.0000 - auc: 0.7783 - prc: 0.1585 - val_loss: 0.2123 - val_Sensitivity: 0.0670 - val_tn: 4848.0000 - val_auc: 0.7673 - val_prc: 0.1251\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1444 - Sensitivity: 0.0117 - tn: 14638.0000 - auc: 0.7793 - prc: 0.1783 - val_loss: 0.2151 - val_Sensitivity: 0.0670 - val_tn: 4837.0000 - val_auc: 0.7671 - val_prc: 0.1186\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1462 - Sensitivity: 0.0100 - tn: 14633.0000 - auc: 0.7718 - prc: 0.1549 - val_loss: 0.2087 - val_Sensitivity: 0.0615 - val_tn: 4855.0000 - val_auc: 0.7663 - val_prc: 0.1261\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1462 - Sensitivity: 0.0134 - tn: 14638.0000 - auc: 0.7720 - prc: 0.1571 - val_loss: 0.2105 - val_Sensitivity: 0.0615 - val_tn: 4847.0000 - val_auc: 0.7643 - val_prc: 0.1247\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1449 - Sensitivity: 0.0084 - tn: 14639.0000 - auc: 0.7821 - prc: 0.1647 - val_loss: 0.2119 - val_Sensitivity: 0.0670 - val_tn: 4833.0000 - val_auc: 0.7645 - val_prc: 0.1202\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1430 - Sensitivity: 0.0084 - tn: 14637.0000 - auc: 0.7884 - prc: 0.1655 - val_loss: 0.2084 - val_Sensitivity: 0.0559 - val_tn: 4840.0000 - val_auc: 0.7641 - val_prc: 0.1189\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1439 - Sensitivity: 0.0033 - tn: 14640.0000 - auc: 0.7845 - prc: 0.1640 - val_loss: 0.2093 - val_Sensitivity: 0.0559 - val_tn: 4837.0000 - val_auc: 0.7648 - val_prc: 0.1170\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1433 - Sensitivity: 0.0050 - tn: 14643.0000 - auc: 0.7852 - prc: 0.1657 - val_loss: 0.2145 - val_Sensitivity: 0.0670 - val_tn: 4831.0000 - val_auc: 0.7648 - val_prc: 0.1132\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1417 - Sensitivity: 0.0084 - tn: 14635.0000 - auc: 0.7930 - prc: 0.1782 - val_loss: 0.2088 - val_Sensitivity: 0.0615 - val_tn: 4837.0000 - val_auc: 0.7649 - val_prc: 0.1144\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1427 - Sensitivity: 0.0100 - tn: 14637.0000 - auc: 0.7927 - prc: 0.1621 - val_loss: 0.2074 - val_Sensitivity: 0.0615 - val_tn: 4837.0000 - val_auc: 0.7642 - val_prc: 0.1167\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1452 - Sensitivity: 0.0100 - tn: 14638.0000 - auc: 0.7840 - prc: 0.1539 - val_loss: 0.2124 - val_Sensitivity: 0.0670 - val_tn: 4832.0000 - val_auc: 0.7639 - val_prc: 0.1134\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1428 - Sensitivity: 0.0167 - tn: 14639.0000 - auc: 0.7880 - prc: 0.1762 - val_loss: 0.2111 - val_Sensitivity: 0.0615 - val_tn: 4831.0000 - val_auc: 0.7638 - val_prc: 0.1134\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1431 - Sensitivity: 0.0033 - tn: 14635.0000 - auc: 0.7914 - prc: 0.1580 - val_loss: 0.2060 - val_Sensitivity: 0.0559 - val_tn: 4836.0000 - val_auc: 0.7641 - val_prc: 0.1152\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1432 - Sensitivity: 0.0050 - tn: 14636.0000 - auc: 0.7892 - prc: 0.1564 - val_loss: 0.2025 - val_Sensitivity: 0.0559 - val_tn: 4839.0000 - val_auc: 0.7649 - val_prc: 0.1150\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1438 - Sensitivity: 0.0100 - tn: 14638.0000 - auc: 0.7822 - prc: 0.1726 - val_loss: 0.2060 - val_Sensitivity: 0.0559 - val_tn: 4839.0000 - val_auc: 0.7643 - val_prc: 0.1135\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1434 - Sensitivity: 0.0067 - tn: 14638.0000 - auc: 0.7924 - prc: 0.1542 - val_loss: 0.2076 - val_Sensitivity: 0.0559 - val_tn: 4839.0000 - val_auc: 0.7653 - val_prc: 0.1131\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1415 - Sensitivity: 0.0100 - tn: 14632.0000 - auc: 0.7967 - prc: 0.1696 - val_loss: 0.2094 - val_Sensitivity: 0.0615 - val_tn: 4836.0000 - val_auc: 0.7645 - val_prc: 0.1123\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1406 - Sensitivity: 0.0117 - tn: 14639.0000 - auc: 0.7951 - prc: 0.1908 - val_loss: 0.2061 - val_Sensitivity: 0.0559 - val_tn: 4838.0000 - val_auc: 0.7649 - val_prc: 0.1151\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1384 - Sensitivity: 0.0167 - tn: 14641.0000 - auc: 0.8123 - prc: 0.1967 - val_loss: 0.2088 - val_Sensitivity: 0.0615 - val_tn: 4835.0000 - val_auc: 0.7635 - val_prc: 0.1118\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1402 - Sensitivity: 0.0100 - tn: 14629.0000 - auc: 0.8044 - prc: 0.1800 - val_loss: 0.2071 - val_Sensitivity: 0.0559 - val_tn: 4835.0000 - val_auc: 0.7631 - val_prc: 0.1114\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1417 - Sensitivity: 0.0100 - tn: 14638.0000 - auc: 0.7953 - prc: 0.1827 - val_loss: 0.2054 - val_Sensitivity: 0.0559 - val_tn: 4837.0000 - val_auc: 0.7625 - val_prc: 0.1132\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1407 - Sensitivity: 0.0117 - tn: 14635.0000 - auc: 0.7995 - prc: 0.1820 - val_loss: 0.2040 - val_Sensitivity: 0.0559 - val_tn: 4839.0000 - val_auc: 0.7615 - val_prc: 0.1136\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1373 - Sensitivity: 0.0100 - tn: 14636.0000 - auc: 0.8145 - prc: 0.1995 - val_loss: 0.2044 - val_Sensitivity: 0.0615 - val_tn: 4838.0000 - val_auc: 0.7608 - val_prc: 0.1159\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1385 - Sensitivity: 0.0100 - tn: 14639.0000 - auc: 0.8095 - prc: 0.1923 - val_loss: 0.2051 - val_Sensitivity: 0.0615 - val_tn: 4837.0000 - val_auc: 0.7602 - val_prc: 0.1146\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1421 - Sensitivity: 0.0084 - tn: 14638.0000 - auc: 0.7895 - prc: 0.1710 - val_loss: 0.2077 - val_Sensitivity: 0.0615 - val_tn: 4837.0000 - val_auc: 0.7643 - val_prc: 0.1131\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1410 - Sensitivity: 0.0100 - tn: 14637.0000 - auc: 0.7968 - prc: 0.1750 - val_loss: 0.2102 - val_Sensitivity: 0.0615 - val_tn: 4833.0000 - val_auc: 0.7636 - val_prc: 0.1119\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1408 - Sensitivity: 0.0167 - tn: 14640.0000 - auc: 0.8000 - prc: 0.1802 - val_loss: 0.2064 - val_Sensitivity: 0.0559 - val_tn: 4836.0000 - val_auc: 0.7624 - val_prc: 0.1116\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1413 - Sensitivity: 0.0100 - tn: 14637.0000 - auc: 0.7995 - prc: 0.1690 - val_loss: 0.2065 - val_Sensitivity: 0.0615 - val_tn: 4830.0000 - val_auc: 0.7627 - val_prc: 0.1110\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1400 - Sensitivity: 0.0067 - tn: 14632.0000 - auc: 0.8057 - prc: 0.1784 - val_loss: 0.2009 - val_Sensitivity: 0.0559 - val_tn: 4842.0000 - val_auc: 0.7629 - val_prc: 0.1124\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1417 - Sensitivity: 0.0050 - tn: 14642.0000 - auc: 0.7986 - prc: 0.1667 - val_loss: 0.2078 - val_Sensitivity: 0.0615 - val_tn: 4831.0000 - val_auc: 0.7629 - val_prc: 0.1089\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1407 - Sensitivity: 0.0167 - tn: 14636.0000 - auc: 0.7957 - prc: 0.1916 - val_loss: 0.2038 - val_Sensitivity: 0.0615 - val_tn: 4839.0000 - val_auc: 0.7617 - val_prc: 0.1116\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1392 - Sensitivity: 0.0167 - tn: 14641.0000 - auc: 0.8016 - prc: 0.2053 - val_loss: 0.2058 - val_Sensitivity: 0.0615 - val_tn: 4835.0000 - val_auc: 0.7610 - val_prc: 0.1112\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1394 - Sensitivity: 0.0134 - tn: 14633.0000 - auc: 0.8064 - prc: 0.1840 - val_loss: 0.2057 - val_Sensitivity: 0.0615 - val_tn: 4835.0000 - val_auc: 0.7619 - val_prc: 0.1083\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1394 - Sensitivity: 0.0167 - tn: 14642.0000 - auc: 0.8056 - prc: 0.1924 - val_loss: 0.2016 - val_Sensitivity: 0.0615 - val_tn: 4838.0000 - val_auc: 0.7604 - val_prc: 0.1151\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1381 - Sensitivity: 0.0067 - tn: 14638.0000 - auc: 0.8172 - prc: 0.1886 - val_loss: 0.2014 - val_Sensitivity: 0.0615 - val_tn: 4839.0000 - val_auc: 0.7616 - val_prc: 0.1121\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1396 - Sensitivity: 0.0184 - tn: 14637.0000 - auc: 0.8045 - prc: 0.1918 - val_loss: 0.2031 - val_Sensitivity: 0.0615 - val_tn: 4838.0000 - val_auc: 0.7606 - val_prc: 0.1120\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1387 - Sensitivity: 0.0117 - tn: 14635.0000 - auc: 0.8085 - prc: 0.1885 - val_loss: 0.2019 - val_Sensitivity: 0.0615 - val_tn: 4839.0000 - val_auc: 0.7601 - val_prc: 0.1181\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1379 - Sensitivity: 0.0067 - tn: 14634.0000 - auc: 0.8136 - prc: 0.1810 - val_loss: 0.1996 - val_Sensitivity: 0.0615 - val_tn: 4840.0000 - val_auc: 0.7590 - val_prc: 0.1177\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1350 - Sensitivity: 0.0117 - tn: 14637.0000 - auc: 0.8273 - prc: 0.2103 - val_loss: 0.1985 - val_Sensitivity: 0.0559 - val_tn: 4840.0000 - val_auc: 0.7590 - val_prc: 0.1174\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1377 - Sensitivity: 0.0134 - tn: 14637.0000 - auc: 0.8161 - prc: 0.1868 - val_loss: 0.1985 - val_Sensitivity: 0.0615 - val_tn: 4848.0000 - val_auc: 0.7587 - val_prc: 0.1172\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1381 - Sensitivity: 0.0167 - tn: 14633.0000 - auc: 0.8112 - prc: 0.1979 - val_loss: 0.2043 - val_Sensitivity: 0.0615 - val_tn: 4839.0000 - val_auc: 0.7577 - val_prc: 0.1093\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1355 - Sensitivity: 0.0117 - tn: 14630.0000 - auc: 0.8293 - prc: 0.1921 - val_loss: 0.2024 - val_Sensitivity: 0.0615 - val_tn: 4836.0000 - val_auc: 0.7579 - val_prc: 0.1092\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1378 - Sensitivity: 0.0184 - tn: 14633.0000 - auc: 0.8103 - prc: 0.1961 - val_loss: 0.1993 - val_Sensitivity: 0.0615 - val_tn: 4841.0000 - val_auc: 0.7573 - val_prc: 0.1142\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1384 - Sensitivity: 0.0084 - tn: 14639.0000 - auc: 0.8113 - prc: 0.2003 - val_loss: 0.1958 - val_Sensitivity: 0.0559 - val_tn: 4859.0000 - val_auc: 0.7569 - val_prc: 0.1189\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1355 - Sensitivity: 0.0167 - tn: 14627.0000 - auc: 0.8227 - prc: 0.2064 - val_loss: 0.2007 - val_Sensitivity: 0.0670 - val_tn: 4837.0000 - val_auc: 0.7558 - val_prc: 0.1086\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1374 - Sensitivity: 0.0117 - tn: 14635.0000 - auc: 0.8145 - prc: 0.1968 - val_loss: 0.2009 - val_Sensitivity: 0.0670 - val_tn: 4834.0000 - val_auc: 0.7561 - val_prc: 0.1076\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1366 - Sensitivity: 0.0134 - tn: 14628.0000 - auc: 0.8240 - prc: 0.1864 - val_loss: 0.1971 - val_Sensitivity: 0.0670 - val_tn: 4838.0000 - val_auc: 0.7556 - val_prc: 0.1110\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1363 - Sensitivity: 0.0100 - tn: 14639.0000 - auc: 0.8199 - prc: 0.2020 - val_loss: 0.1998 - val_Sensitivity: 0.0670 - val_tn: 4835.0000 - val_auc: 0.7557 - val_prc: 0.1076\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1333 - Sensitivity: 0.0184 - tn: 14632.0000 - auc: 0.8307 - prc: 0.2280 - val_loss: 0.1994 - val_Sensitivity: 0.0670 - val_tn: 4834.0000 - val_auc: 0.7556 - val_prc: 0.1078\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1328 - Sensitivity: 0.0167 - tn: 14634.0000 - auc: 0.8335 - prc: 0.2292 - val_loss: 0.1933 - val_Sensitivity: 0.0615 - val_tn: 4842.0000 - val_auc: 0.7541 - val_prc: 0.1106\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1354 - Sensitivity: 0.0184 - tn: 14635.0000 - auc: 0.8260 - prc: 0.2078 - val_loss: 0.1949 - val_Sensitivity: 0.0670 - val_tn: 4847.0000 - val_auc: 0.7527 - val_prc: 0.1126\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1348 - Sensitivity: 0.0201 - tn: 14634.0000 - auc: 0.8286 - prc: 0.2035 - val_loss: 0.1994 - val_Sensitivity: 0.0670 - val_tn: 4838.0000 - val_auc: 0.7529 - val_prc: 0.1072\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1343 - Sensitivity: 0.0134 - tn: 14637.0000 - auc: 0.8292 - prc: 0.2102 - val_loss: 0.1959 - val_Sensitivity: 0.0670 - val_tn: 4843.0000 - val_auc: 0.7523 - val_prc: 0.1098\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1325 - Sensitivity: 0.0167 - tn: 14635.0000 - auc: 0.8401 - prc: 0.2276 - val_loss: 0.1973 - val_Sensitivity: 0.0670 - val_tn: 4841.0000 - val_auc: 0.7524 - val_prc: 0.1071\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1347 - Sensitivity: 0.0134 - tn: 14632.0000 - auc: 0.8285 - prc: 0.2002 - val_loss: 0.1957 - val_Sensitivity: 0.0670 - val_tn: 4843.0000 - val_auc: 0.7507 - val_prc: 0.1091\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1328 - Sensitivity: 0.0234 - tn: 14637.0000 - auc: 0.8346 - prc: 0.2319 - val_loss: 0.1954 - val_Sensitivity: 0.0670 - val_tn: 4847.0000 - val_auc: 0.7509 - val_prc: 0.1142\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1320 - Sensitivity: 0.0217 - tn: 14634.0000 - auc: 0.8394 - prc: 0.2346 - val_loss: 0.1978 - val_Sensitivity: 0.0726 - val_tn: 4839.0000 - val_auc: 0.7515 - val_prc: 0.1139\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1343 - Sensitivity: 0.0201 - tn: 14632.0000 - auc: 0.8309 - prc: 0.2099 - val_loss: 0.1948 - val_Sensitivity: 0.0670 - val_tn: 4862.0000 - val_auc: 0.7521 - val_prc: 0.1209\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1345 - Sensitivity: 0.0184 - tn: 14635.0000 - auc: 0.8277 - prc: 0.2089 - val_loss: 0.1940 - val_Sensitivity: 0.0615 - val_tn: 4865.0000 - val_auc: 0.7517 - val_prc: 0.1213\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1328 - Sensitivity: 0.0201 - tn: 14637.0000 - auc: 0.8366 - prc: 0.2326 - val_loss: 0.1983 - val_Sensitivity: 0.0726 - val_tn: 4852.0000 - val_auc: 0.7503 - val_prc: 0.1175\n"
     ]
    }
   ],
   "source": [
    "annpreds = []\n",
    "for X, y, X_test in zip(dX_train, dy_train, dX_test):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=0)\n",
    "    model4.fit(X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping])\n",
    "    annpreds.append(model4.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.740339069862733,\n",
       " 0.7378020747728111,\n",
       " 0.790027628271271,\n",
       " 0.7577701836544609,\n",
       " 0.7550797869751049]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_score = []\n",
    "for x in range(0,5):\n",
    "    ann_score.append(roc_auc_score(dy_test[x], annpreds[x]))\n",
    "ann_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(dX_train[0], dy_train[0])\n",
    "def rf_feat_importance(model, X):\n",
    "    return pd.DataFrame({'cols':X.columns, 'imp':model.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "fi = rf_feat_importance(model, X)\n",
    "fi[:10]\n",
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "plot_fi(fi[:20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2.fit(dX_train[0], dy_train[0])\n",
    "fi = rf_feat_importance(model2, X)\n",
    "plot_fi(fi[:20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchen/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kchen/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kchen/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kchen/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kchen/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrpreds = []\n",
    "model3 = LogisticRegression()\n",
    "for X, y, X_test in zip(dX_train, dy_train, dX_test):\n",
    "    model3.fit(X, y)\n",
    "    lrpreds.append(model3.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score = []\n",
    "for x in range(0,5):\n",
    "    lr_score.append(roc_auc_score(dy_test[x], lrpreds[x][:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7035484531858226,\n",
       " 0.7177868295994568,\n",
       " 0.7151693551278628,\n",
       " 0.7417554540842213,\n",
       " 0.7417554540842213]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network: 0.756 (0.73-0.782)\n"
     ]
    }
   ],
   "source": [
    "ann_mean = np.mean(ann_score)\n",
    "ann_confidence = st.t.interval(0.95, len(ann_score)-1, loc=ann_mean, scale=st.sem(ann_score))\n",
    "\n",
    "print('Neural Network:', round(ann_mean,3), '('+str(round(ann_confidence[0],3))+'-'+str(round(ann_confidence[1],3))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.724 (0.703-0.745)\n"
     ]
    }
   ],
   "source": [
    "lr_mean = np.mean(lr_score)\n",
    "lr_confidence = st.t.interval(0.95, len(lr_score)-1, loc=lr_mean, scale=st.sem(lr_score))\n",
    "\n",
    "print('Logistic Regression:', round(lr_mean,3), '('+str(round(lr_confidence[0],3))+'-'+str(round(lr_confidence[1],3))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network: 0.134 (0.085-0.183)\n"
     ]
    }
   ],
   "source": [
    "ann_prc = []\n",
    "for x in range(0,5):\n",
    "    ann_prc.append(average_precision_score(dy_test[x], annpreds[x]))\n",
    "\n",
    "ann_prc_mean = np.mean(ann_prc)\n",
    "ann_prc_confidence = st.t.interval(0.95, len(ann_prc)-1, loc=ann_prc_mean, scale=st.sem(ann_prc))\n",
    "\n",
    "print('Neural Network:', round(ann_prc_mean,3), '('+str(round(ann_prc_confidence[0],3))+'-'+str(round(ann_prc_confidence[1],3))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.097 (0.086-0.108)\n"
     ]
    }
   ],
   "source": [
    "lr_prc = []\n",
    "for x in range(0,5):\n",
    "    lr_prc.append(average_precision_score(dy_test[x], lrpreds[x][:,1]))\n",
    "\n",
    "lr_prc_mean = np.mean(lr_prc)\n",
    "lr_prc_confidence = st.t.interval(0.95, len(lr_prc)-1, loc=lr_prc_mean, scale=st.sem(lr_prc))\n",
    "\n",
    "print('Logistic Regression:', round(lr_prc_mean,3), '('+str(round(lr_prc_confidence[0],3))+'-'+str(round(lr_prc_confidence[1],3))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hep_results.txt', 'w') as f:\n",
    "    f.write('Logistic Regression: '+str(round(lr_mean,3))+' ('+str(round(lr_confidence[0],3))+'-'+str(round(lr_confidence[1],3))+')\\n')\n",
    "    f.write('Neural Network: '+str(round(ann_mean,3))+' ('+str(round(ann_confidence[0],3))+'-'+str(round(ann_confidence[1],3))+')\\n')\n",
    "    f.write('AUPRC\\n')\n",
    "    f.write('Logistic Regression: '+str(round(lr_prc_mean,3))+' ('+str(round(lr_prc_confidence[0],3))+'-'+str(round(lr_prc_confidence[1],3))+')\\n')\n",
    "    f.write('Neural Network: '+str(round(ann_prc_mean,3))+' ('+str(round(ann_prc_confidence[0],3))+'-'+str(round(ann_prc_confidence[1],3))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep_ann_tpr = []\n",
    "hep_ann_fpr = []\n",
    "for x in range(0,5):\n",
    "    fpr, tpr, _ = roc_curve(dy_test[x], annpreds[x], drop_intermediate=False)\n",
    "    hep_ann_tpr.append(tpr)\n",
    "    hep_ann_fpr.append(fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5081\n",
      "5080\n",
      "5080\n",
      "5079\n",
      "5080\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,5):\n",
    "    print(len(hep_ann_tpr[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x in range(0,5):\n",
    "    diff = len(hep_ann_tpr[x]) - 310\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_ann_tpr[x]))\n",
    "        hep_ann_tpr[x] = np.delete(hep_ann_tpr[x],ind)\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_ann_fpr[x]) - 310\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_ann_fpr[x]))\n",
    "        hep_ann_fpr[x] = np.delete(hep_ann_fpr[x],ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mean_hep_ann_tpr' (list)\n",
      "Stored 'mean_hep_ann_fpr' (list)\n"
     ]
    }
   ],
   "source": [
    "mean_hep_ann_tpr = [np.mean(k) for k in zip(*hep_ann_tpr)]\n",
    "mean_hep_ann_fpr = [np.mean(k) for k in zip(*hep_ann_fpr)]\n",
    "%store mean_hep_ann_tpr\n",
    "%store mean_hep_ann_fpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mean_hep_lr_tpr' (list)\n",
      "Stored 'mean_hep_lr_fpr' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hep_lr_tpr = []\n",
    "hep_lr_fpr = []\n",
    "for x in range(0,5):\n",
    "    fpr, tpr, _ = roc_curve(dy_test[x], lrpreds[x][:,1])\n",
    "    hep_lr_tpr.append(tpr)\n",
    "    hep_lr_fpr.append(fpr)\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_lr_tpr[x]) - 310\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_lr_tpr[x]))\n",
    "        hep_lr_tpr[x] = np.delete(hep_lr_tpr[x],ind)\n",
    "\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_lr_fpr[x]) - 310\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_lr_fpr[x]))\n",
    "        hep_lr_fpr[x] = np.delete(hep_lr_fpr[x],ind)\n",
    "\n",
    "\n",
    "mean_hep_lr_tpr = [np.mean(k) for k in zip(*hep_lr_tpr)]\n",
    "mean_hep_lr_fpr = [np.mean(k) for k in zip(*hep_lr_fpr)]\n",
    "%store mean_hep_lr_tpr\n",
    "%store mean_hep_lr_fpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hep_lr_rec = []\n",
    "hep_lr_prec = []\n",
    "for x in range(0,5):\n",
    "    prec, rec, _ = precision_recall_curve(dy_test[x], lrpreds[x][:,1])\n",
    "    hep_lr_rec.append(rec)\n",
    "    hep_lr_prec.append(prec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4970\n",
      "4982\n",
      "4866\n",
      "5047\n",
      "5047\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,5):\n",
    "    print(len(hep_lr_rec[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mean_hep_lr_rec' (list)\n",
      "Stored 'mean_hep_lr_prec' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_lr_rec[x]) - 4800\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_lr_rec[x]))\n",
    "        hep_lr_rec[x] = np.delete(hep_lr_rec[x],ind)\n",
    "\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_lr_prec[x]) - 4800\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_lr_prec[x]))\n",
    "        hep_lr_prec[x] = np.delete(hep_lr_prec[x],ind)\n",
    "\n",
    "mean_hep_lr_rec = [np.mean(k) for k in zip(*hep_lr_rec)]\n",
    "mean_hep_lr_prec = [np.mean(k) for k in zip(*hep_lr_prec)]\n",
    "%store mean_hep_lr_rec\n",
    "%store mean_hep_lr_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb12c33d490>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mean_hep_lr_rec, mean_hep_lr_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mean_hep_ann_rec' (list)\n",
      "Stored 'mean_hep_ann_prec' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hep_ann_rec = []\n",
    "hep_ann_prec = []\n",
    "for x in range(0,5):\n",
    "    prec, rec, _ = precision_recall_curve(dy_test[x], annpreds[x])\n",
    "    hep_ann_rec.append(rec)\n",
    "    hep_ann_prec.append(prec)\n",
    "\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_ann_rec[x]) - 4500\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_ann_rec[x]))\n",
    "        hep_ann_rec[x] = np.delete(hep_ann_rec[x],ind)\n",
    "\n",
    "for x in range(0,5):\n",
    "    diff = len(hep_ann_prec[x]) - 4500\n",
    "    for _ in range(diff):\n",
    "        ind = randrange(len(hep_ann_prec[x]))\n",
    "        hep_ann_prec[x] = np.delete(hep_ann_prec[x],ind)\n",
    "\n",
    "mean_hep_ann_rec = [np.mean(k) for k in zip(*hep_ann_rec)]\n",
    "mean_hep_ann_prec = [np.mean(k) for k in zip(*hep_ann_prec)]\n",
    "%store mean_hep_ann_rec\n",
    "%store mean_hep_ann_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hep_ann_tpr = []\n",
    "hep_ann_fpr = []\n",
    "for x in range(0,5):\n",
    "    fpr, tpr, _ = roc_curve(dy_test[x], annpreds[x])\n",
    "    hep_ann_tpr.append(tpr)\n",
    "    hep_ann_fpr.append(fpr)\n",
    "hep_ann_tpr_array = [np.array(x) for x in hep_ann_tpr]\n",
    "mean_hep_ann_tpr = [np.mean(k) for k in zip(*hep_ann_tpr_array)]\n",
    "hep_ann_fpr_array = [np.array(x) for x in hep_ann_fpr]\n",
    "mean_hep_ann_fpr = [np.mean(k) for k in zip(*hep_ann_fpr_array)]\n",
    "%store mean_hep_ann_tpr\n",
    "%store mean_hep_ann_fpr\n",
    "\n",
    "hep_lr_tpr = []\n",
    "hep_lr_fpr = []\n",
    "for x in range(0,5):\n",
    "    fpr, tpr, _ = roc_curve(dy_test[x], lrpreds[x][:,1])\n",
    "    hep_lr_tpr.append(tpr)\n",
    "    hep_lr_fpr.append(fpr)\n",
    "hep_lr_tpr_array = [np.array(x) for x in hep_lr_tpr]\n",
    "mean_hep_lr_tpr = [np.mean(k) for k in zip(*hep_lr_tpr_array)]\n",
    "hep_lr_fpr_array = [np.array(x) for x in hep_lr_fpr]\n",
    "mean_hep_lr_fpr = [np.mean(k) for k in zip(*hep_lr_fpr_array)]\n",
    "%store mean_hep_lr_tpr\n",
    "%store mean_hep_lr_fpr\n",
    "hep_ann_rec = []\n",
    "hep_ann_prec = []\n",
    "for x in range(0,5):\n",
    "    prec, rec, _ = precision_recall_curve(dy_test[x], annpreds[x])\n",
    "    hep_ann_rec.append(rec)\n",
    "    hep_ann_prec.append(prec)\n",
    "hep_ann_rec_array = [np.array(x) for x in hep_ann_rec]\n",
    "mean_hep_ann_rec = [np.mean(k) for k in zip(*hep_ann_rec_array)]\n",
    "hep_ann_prec_array = [np.array(x) for x in hep_ann_prec]\n",
    "mean_hep_ann_prec = [np.mean(k) for k in zip(*hep_ann_prec_array)]\n",
    "%store mean_hep_ann_rec\n",
    "%store mean_hep_ann_prec\n",
    "\n",
    "hep_lr_rec = []\n",
    "hep_lr_prec = []\n",
    "for x in range(0,5):\n",
    "    prec, rec, _ = precision_recall_curve(dy_test[x], lrpreds[x][:,1])\n",
    "    hep_lr_rec.append(rec)\n",
    "    hep_lr_prec.append(prec)\n",
    "hep_lr_rec_array = [np.array(x) for x in hep_lr_rec]\n",
    "mean_hep_lr_rec = [np.mean(k) for k in zip(*hep_lr_rec_array)]\n",
    "hep_lr_prec_array = [np.array(x) for x in hep_lr_prec]\n",
    "mean_hep_lr_prec = [np.mean(k) for k in zip(*hep_lr_prec_array)]\n",
    "%store mean_hep_lr_rec\n",
    "%store mean_hep_lr_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.metrics import specificity_score\n",
    "thresh = np.arange(0, 1, 0.01)\n",
    "#calculate recall at 10 thresholds\n",
    "annrecall_list = []\n",
    "for i in thresh:\n",
    "    annrecall_list.append(recall_score(dy_test[1], annpreds[1] > i))\n",
    "#calculate spec at 10 thresholds\n",
    "annspec_list = []\n",
    "for i in thresh:\n",
    "    annspec_list.append(specificity_score(dy_test[1], annpreds[1] > i))\n",
    "from matplotlib import pyplot as plt\n",
    "#plot recall vs threshold\n",
    "plt.plot(thresh, annrecall_list, label = 'Sensitivity')\n",
    "plt.plot(thresh, annspec_list, color = 'red', label = 'Specificity')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Sensitivity and Specificity')\n",
    "plt.title('Sensitivity and Specificity by Threshold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "thresh = np.arange(0, 1, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculate recall at 10 thresholds\n",
    "lrrecall_list = []\n",
    "for i in thresh:\n",
    "    lrrecall_list.append(recall_score(dy_test[1], lrpreds[1][:,1] > i))\n",
    "#calculate spec at 10 thresholds\n",
    "lrspec_list = []\n",
    "for i in thresh:\n",
    "    lrspec_list.append(specificity_score(dy_test[1], lrpreds[1][:,1] > i))\n",
    "from matplotlib import pyplot as plt\n",
    "#plot recall vs threshold\n",
    "plt.plot(thresh, lrrecall_list, label = 'Sensitivity')\n",
    "plt.plot(thresh, lrspec_list, color = 'red', label = 'Specificity')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Sensitivity and Specificity')\n",
    "plt.title('Sensitivity and Specificity by Threshold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7192982456140351\n",
      "0.6008146639511202\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(dy_test[1], lrpreds[1][:,1] > 0.03))\n",
    "print(specificity_score(dy_test[1], lrpreds[1][:,1] > 0.03))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7543859649122807\n",
      "0.5869653767820774\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(dy_test[1], annpreds[1] > 0.125))\n",
    "print(specificity_score(dy_test[1], annpreds[1] > 0.125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn import metrics\n",
    "\n",
    "def auc(X, Y):\n",
    "    return 1/(len(X)*len(Y)) * sum([kernel(x, y) for x in X for y in Y])\n",
    "def kernel(X, Y):\n",
    "    return .5 if Y==X else int(Y < X)\n",
    "def structural_components(X, Y):\n",
    "    V10 = [1/len(Y) * sum([kernel(x, y) for y in Y]) for x in X]\n",
    "    V01 = [1/len(X) * sum([kernel(x, y) for x in X]) for y in Y]\n",
    "    return V10, V01\n",
    "    \n",
    "\n",
    "def get_S_entry(V_A, V_B, auc_A, auc_B):\n",
    "    return 1/(len(V_A)-1) * sum([(a-auc_A)*(b-auc_B) for a,b in zip(V_A, V_B)])\n",
    "def z_score(var_A, var_B, covar_AB, auc_A, auc_B):\n",
    "    return (auc_A - auc_B)/((var_A + var_B - 2*covar_AB)**(.5))\n",
    "\n",
    "\n",
    "p = []\n",
    "z = []\n",
    "# Model A (random) vs. \"good\" model B\n",
    "for x in range(0,5):\n",
    "    preds_A = annpreds[x]\n",
    "    preds_B = lrpreds[x][:,1]\n",
    "    actual = dy_test[x]\n",
    "\n",
    "    actual = actual.array\n",
    "\n",
    "    def group_preds_by_label(preds, actual):\n",
    "        X = [p for (p, a) in zip(preds, actual) if a]\n",
    "        Y = [p for (p, a) in zip(preds, actual) if not a]\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    X_A, Y_A = group_preds_by_label(preds_A, actual)\n",
    "    X_B, Y_B = group_preds_by_label(preds_B, actual)\n",
    "    V_A10, V_A01 = structural_components(X_A, Y_A)\n",
    "    V_B10, V_B01 = structural_components(X_B, Y_B)\n",
    "    auc_A = auc(X_A, Y_A)\n",
    "    auc_B = auc(X_B, Y_B)\n",
    "\n",
    "\n",
    "    # Compute entries of covariance matrix S (covar_AB = covar_BA)\n",
    "    var_A = (get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1/len(V_A10)\n",
    "            + get_S_entry(V_A01, V_A01, auc_A, auc_A) * 1/len(V_A01))\n",
    "    var_B = (get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1/len(V_B10)\n",
    "            + get_S_entry(V_B01, V_B01, auc_B, auc_B) * 1/len(V_B01))\n",
    "    covar_AB = (get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1/len(V_A10)\n",
    "                + get_S_entry(V_A01, V_B01, auc_A, auc_B) * 1/len(V_A01))\n",
    "\n",
    "    # Two tailed test\n",
    "    z.append(z_score(var_A, var_B, covar_AB, auc_A, auc_B))\n",
    "    p.append(st.norm.sf(abs(z[x-1]))*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0008414236000672049,\n",
       " 0.0008414236000672049,\n",
       " 0.06992098180299783,\n",
       " 9.733662959044024e-09,\n",
       " 0.1856597792893646]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05145272360523197"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p)/(len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
